resume:
load_encoder: True
load_fuse_generator: True
device: cuda:0
image_size: 224
K: 1 # temporal sequence length - no temporal data used here
deterministic: False
seed: 13809409134

train:

  lr: 1e-3
  num_epochs: 10
  batch_size: 2
  accumulate_steps: 5
  num_workers: 0 # Using multiprocessing in Dataset
  log_path: logs/exp_only
  log_losses_every: 10
  visualize_every: 50
  mask_ratio: 0.01  # % pixel to be retained inside the face mask
  mask_dilation_radius: 10 # dilation of the initial face mask
  save_every: 15000 # save model every n epochs
  use_wandb: False
  Ke: 1 # number of repeated frames for 2nd cycle path
  # samples_per_epoch: 354178 # Max Cull 430095 # Culled 472033 DEPRECATED
  use_base_model_for_regularization: True  # use the base model for regularization - when False the regularization is wrt zero
  resume_epoch: 0
  train_scale_min: 1.2  # min scale for data augmentation during training
  train_scale_max: 1.8 # max scale for data augmentation during training
  stored_scale: 2.2 # scale at which images were stored in
  test_scale: 1.6 # fixed scale for testing

  loss_weights:
    landmark_loss: 100.0   # landmark loss weight
    perceptual_vgg_loss: 10.0  # RECONSTRUCTION - perceptual vgg loss weight
    reconstruction_loss: 10.0  # RECONSTRUCTION - l1 loss weight
    emotion_loss: 0.0  # extra emotion loss weight 
    jaw_regularization: 10.0
    expression_regularization: 1.0
    shape_regularization: 0.0
    pose_regularization: 0.0
    cam_regularization: 0.0
    cycle_loss: 0.0  # CYCLE loss
    mica_loss: 0

  optimize_base_pose: False
  optimize_base_shape: False
  optimize_base_expression: False  # Do not optimize original network
  optimize_tater: True
  optimize_generator: False

  # automatically tunable hyperparameters - just declared here
  freeze_base_encoders_in_second_path: True
  freeze_generator_in_second_path: False

# architectural details - backbones and number of FLAME components
arch:
  backbone_pose: tf_mobilenetv3_small_minimal_100    
  backbone_shape: tf_mobilenetv3_large_minimal_100
  backbone_expression: tf_mobilenetv3_large_minimal_100
  num_expression: 50 
  num_shape: 300 # same as MICA
  use_eyelids: True
  enable_fuse_generator: True 

  TATER:
    interp_down_residual: True
    use_interp_linear_layer: False
    downsample_rate: 3

    Expression:
      use_base_encoder: False
      linear_size: 960
      init_zero: True

      Transformer:
        positional_embedding: "Sinusoidal"
        num_layers: 3

        final_dropout:
          enable: False
          prob: 0.1
        
        attention:
          hidden_size: 960
          hidden_size_2: 1920
          num_attention_heads: 2
          attention_probs_dropout_prob: 0.1

          layer_norm_eps: 1e-12

    Shape:
      use_base_encoder: True
      linear_size: 960
      init_zero: True

      Transformer:
        positional_embedding: "Sinusoidal"
        num_layers: 3

        final_dropout:
          enable: False
          prob: 0.1
        
        attention:
          hidden_size: 960
          hidden_size_2: 1920
          num_attention_heads: 2
          attention_probs_dropout_prob: 0.1

          layer_norm_eps: 1e-12

    Pose:
      use_base_encoder: True
      linear_size: 576
      init_zero: True

      Transformer:
        positional_embedding: "Sinusoidal"
        num_layers: 3

        final_dropout:
          enable: False
          prob: 0.1
        
        attention:
          hidden_size: 576
          hidden_size_2: 1152
          num_attention_heads: 2
          attention_probs_dropout_prob: 0.1

          layer_norm_eps: 1e-12

    text_emb_size: 768

render:
  full_head: False  # full FLAME rendering

dataset:
  iHiTOP_hdf5_path: /local/PTSD_STOP/iHiTOP_TATER_Data/temp
  iHiTOP_aug_workers: 8
  iHiTOP_frame_step: 1

  # Data culling parameters
  removed_frames_threshold: 0.15
  max_seg_len: 120
  min_seg_len: 9
  data_idxs: /local/PTSD_STOP/TATER/data_idxs/remove_85_max_120_min_9_v1.npy
  final_idxs: /local/PTSD_STOP/TATER/final_idxs/exp_only.npy
  bad_files: /local/PTSD_STOP/TATER/final_idxs/bad_exp.npy

  # percentage of data to use for train val test
  iHiTOP_train_percentage: 0.8
  iHiTOP_val_percentage: 0.1
  iHiTOP_test_percentage: 0.1

  # percentage of data to use for each dataset
  LRS3_percentage: 0.0
  LRS3_temporal_sampling: False
  MEAD_percentage: 1.0
  FFHQ_percentage: 0.0 
  CelebA_percentage: 0.0 
  MEAD_sides_percentage: 0.0
  sample_full_video_for_testing: False

