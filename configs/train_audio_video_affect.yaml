resume: /local/PTSD_STOP/TATER/pretrained_models/SMIRK_em1.pt
load_encoder: true
load_fuse_generator: true
device: cuda:0
image_size: 224
K: 1
deterministic: false
seed: 13809409134
threads_per_rank: 4
train:
  min_lr: 1.0e-05
  max_lr: 3.0e-05
  iterations_until_max_lr: 60000
  num_epochs: 10
  batch_size: 8
  accumulate_steps: 1
  num_workers: 2
  log_path: logs/train_affect_multiple
  log_losses_every: 5
  visualize_every: 50
  mask_ratio: 0.0125
  series_pixel_sampling: true
  mask_dilation_radius: 10
  mask_mouth: false
  swap_mouth: false
  save_every: 500
  use_wandb: false
  Ke: 1
  use_base_model_for_regularization: true
  resume_epoch: 0
  train_scale_min: 1.2
  train_scale_max: 1.8
  stored_scale: 2.2
  test_scale: 1.6
  enable_residual_scaling: false
  initial_residual_scale: 0.001
  max_res_scale_iterations: 15000
  residual_schedule: cosine
  use_one_cycle_lr: false
  max_batch_len: 60
  split_overlap: 0
  token_masking: None
  masking_rate: 1.0
  max_masked: 0.2
  min_masked: 0.08
  modality_dropout: true
  video_dropout_rate: 0.5
  audio_dropout_rate: 0.4
  phoneme_onehot: false
  loss_weights:
    landmark_loss: 1000.0
    perceptual_vgg_loss: 10.0
    reconstruction_loss: 100.0
    gan_loss: 10.0
    emotion_loss: 1.0
    jaw_regularization: 5.0
    eyelid_regularization: 15.0
    expression_regularization: 15.0
    shape_regularization: 50.0
    pose_regularization: 50.0
    cam_regularization: 50.0
    exp_res_regularization: 0.0
    shape_res_regularization: 0.0
    pose_res_regularization: 0.0
    cycle_loss: 1.0
    mica_loss: 0.0
    landmark_mouth_dist_loss: 10.0
    lipreading_loss: 10.0
    sym_lipreading_loss: 4.0
    phoneme_loss: 0.0
    velocity_loss: 5000.0
    recon_velocity_loss: 5.0
    pose_smoothness_loss: 1.0
  optimize_base_pose: true
  optimize_base_shape: true
  optimize_base_expression: true
  optimize_tater: true
  optimize_generator: true
  optimize_discriminator: true
  optimize_phoneme_classifier: false
  freeze_encoder_in_first_path: false
  freeze_generator_in_first_path: false
  freeze_discriminator_in_first_path: false
  freeze_encoder_in_second_path: false
  freeze_generator_in_second_path: false
arch:
  backbone_pose: tf_mobilenetv3_small_minimal_100
  backbone_shape: tf_mobilenetv3_large_minimal_100
  backbone_expression: tf_mobilenetv3_large_minimal_100
  num_expression: 50
  num_shape: 300
  use_eyelids: true
  enable_fuse_generator: true
  enable_temporal_generator: false
  tater_base: true
  TATER:
    interp_down_residual: false
    use_interp_linear_layer: false
    downsample_rate: 3
    apply_linear_after_res: false
    Expression:
      use_base_encoder: false
      use_audio: false
      use_latent: true
      use_linear: true
      linear_size: 960
      use_linear_downsample: false
      add_to_flame: true
      init_near_zero: false
      init_scale: 1.0e-09
      pretrain_path: ''
      Transformer:
        positional_embedding: Sinusoidal
        num_layers: 3
        final_dropout:
          enable: false
          prob: 0.1
        attention:
          hidden_size: 960
          hidden_size_2: 1920
          num_attention_heads: 4
          attention_probs_dropout_prob: 0.1
          layer_norm_eps: 1.0e-12
    Shape:
      use_base_encoder: true
      use_linear: true
      use_latent: true
      add_to_flame: true
      linear_size: 320
      use_linear_downsample: true
      init_near_zero: false
      init_scale: 1.0e-09
      pretrain_path: /local/PTSD_STOP/TATER/logs/train_shape_final_v2/model_0_5000.pt
      Transformer:
        positional_embedding: Sinusoidal
        num_layers: 5
        final_dropout:
          enable: false
          prob: 0.1
        attention:
          hidden_size: 320
          hidden_size_2: 640
          num_attention_heads: 4
          attention_probs_dropout_prob: 0.1
          layer_norm_eps: 1.0e-12
    Pose:
      use_base_encoder: true
      use_linear: true
      use_latent: true
      add_to_flame: true
      linear_size: 192
      use_linear_downsample: true
      init_near_zero: false
      init_scale: 1.0e-09
      pretrain_path: ''
      Transformer:
        positional_embedding: Sinusoidal
        num_layers: 5
        final_dropout:
          enable: false
          prob: 0.1
        attention:
          hidden_size: 192
          hidden_size_2: 384
          num_attention_heads: 4
          attention_probs_dropout_prob: 0.1
          layer_norm_eps: 1.0e-12
    text_emb_size: 768

    Affect_Decoder:
        linear_size: 1920
  Phoneme_Classifier:
    enable: false
    type: Linear
    use_latent: true
    Transformer:
      positional_embedding: Sinusoidal
      num_layers: 2
      final_dropout:
        enable: false
        prob: 0.1
      attention:
        hidden_size: 56
        hidden_size_2: 112
        num_attention_heads: 2
        attention_probs_dropout_prob: 0.1
        layer_norm_eps: 1.0e-12
render:
  full_head: false
dataset:
  iHiTOP:
    hdf5_path: /local/PTSD_STOP/iHiTOP_Preprocessed/data
    frame_step: 1
    max_data_idxs: 190672

    # Data culling parameters
    removed_frames_threshold: 0.1
    max_seg_len: 9999999
    min_seg_len: 9
    data_idxs: /local/PTSD_STOP/TATER/data_idxs/all_data_idxs_affect_300K_v3.npy
    # all_seg_idxs: /local/PTSD_STOP/TATER/data_idxs/all_seg_idxs_F3.npy
    # effective_seg_count: /local/PTSD_STOP/TATER/data_idxs/all_data_count_F3.npy
    final_idxs_val: /local/PTSD_STOP/TATER/final_idxs/all_data_idxs_affect_300K_val_v3.npy
    final_idxs_train: /local/PTSD_STOP/TATER/final_idxs/all_data_idxs_affect_300K_train_v3.npy
    final_idxs_test: /local/PTSD_STOP/TATER/final_idxs/all_data_idxs_affect_300K_test_v3.npy
    final_mask_train: /local/PTSD_STOP_pk/train_mask_affect_v3.npy
    final_mask_val: /local/PTSD_STOP_pk/val_mask_affect_v3.npy
    final_mask_test: /local/PTSD_STOP_pk/test_mask_affect_v3.npy
    bad_files: /local/PTSD_STOP/TATER/final_idxs/all_data_idxs_affect_300K_bad_files_v3.npy

    valence_transform: /local/PTSD_STOP/iHiTOP_Preprocessed/quantile_transforms/valence/quantile_transformer.pkl
    arousal_transform: /local/PTSD_STOP/iHiTOP_Preprocessed/quantile_transforms/arousal/quantile_transformer.pkl

    train_percentage: 0.90
    val_percentage: 0.05
    test_percentage: 0.05
  VOCASET:
    data_path: /home/arivero/VOCA
    frame_step: 1
    removed_frames_threshold: 0.15
    max_seg_len: 9999999
    min_seg_len: 3
    final_idxs: /local/PTSD_STOP/TATER/final_idxs/all_final_idxs_VOCASET.npy
    train_percentage: 1.0
    val_percentage: 0.0
    test_percentage: 0.0
  EXT:
    data_path: /home/arivero/SB_Val/data_large
    frame_step: 1
    train_percentage: 0.0
    val_percentage: 1.0
    test_percentage: 0.0
  LRS3_percentage: 0.0
  LRS3_temporal_sampling: false
  MEAD_percentage: 1.0
  FFHQ_percentage: 0.0
  CelebA_percentage: 0.0
  MEAD_sides_percentage: 0.0
  sample_full_video_for_testing: false
