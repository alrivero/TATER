resume:
load_encoder: True
load_fuse_generator: True
device: cuda:0
image_size: 224
K: 1 # temporal sequence length - no temporal data used here
deterministic: False
seed: 13809409134
threads_per_rank: -1

train:
  min_lr: 1e-5
  max_lr: 3e-5
  iterations_until_max_lr: 60000
  num_epochs: 10
  batch_size: 1
  accumulate_steps: 1
  num_workers: 6  # Using multiprocessing in Dataset
  log_path: logs/train_audio_video_final_v7
  log_losses_every: 10
  visualize_every: 50
  mask_ratio: 0.015  # % pixel to be retained inside the face mask
  series_pixel_sampling: True
  mask_dilation_radius: 10 # dilation of the initial face mask
  mask_mouth: False
  swap_mouth: False
  save_every: 10000 # save model every n epochs
  use_wandb: False
  Ke: 1 # number of repeated frames for 2nd cycle path
  # samples_per_epoch: 354178 # Max Cull 430095 # Culled 472033 DEPRECATED
  use_base_model_for_regularization: True  # use the base model for regularization - when False the regularization is wrt zero
  resume_epoch: 0
  train_scale_min: 1.2  # min scale for data augmentation during training
  train_scale_max: 1.8 # max scale for data augmentation during training
  stored_scale: 2.2 # scale at which images were stored in
  test_scale: 1.6 # fixed scale for testing
  enable_residual_scaling: False
  initial_residual_scale: 1e-3
  max_res_scale_iterations: 15000
  residual_schedule: "cosine"
  use_one_cycle_lr: False
  max_batch_len: 60
  split_overlap: 0
  token_masking: "Phoneme"
  masking_rate: 1.0
  max_masked: 0.2
  min_masked: 0.08
  modality_dropout: True
  video_dropout_rate: 0.5
  audio_dropout_rate: 0.4
  phoneme_onehot: True

# Doubled landmark, 10x pose cam, 10x less expression
# * 2.5
  loss_weights:
    landmark_loss: 1000.0   # landmark loss weight
    perceptual_vgg_loss: 10.0  # RECONSTRUCTION - perceptual vgg loss weight
    reconstruction_loss: 100.0  # RECONSTRUCTION - l1 loss weight
    emotion_loss: 1.0  # extra emotion loss weight 
    jaw_regularization: 5.0
    eyelid_regularization: 15.0
    expression_regularization: 15.0
    shape_regularization: 50.0
    pose_regularization: 50.0
    cam_regularization: 50.0
    exp_res_regularization: 0.0
    shape_res_regularization: 0.0
    pose_res_regularization: 0.0
    cycle_loss: 1.0  # CYCLE loss
    mica_loss: 0.0
    landmark_mouth_dist_loss: 10.0
    lipreading_loss: 10.0
    phoneme_loss: 0.0
    velocity_loss: 10000.0
    recon_velocity_loss: 10.0
    pose_smoothness_loss: 1.0

  optimize_base_pose: False
  optimize_base_shape: False
  optimize_base_expression: False  # Do not optimize original network
  optimize_tater: True
  optimize_generator: True
  optimize_phoneme_classifier: False

  # automatically tunable hyperparameters - just declared here
  freeze_encoder_in_second_path: False
  freeze_generator_in_second_path: False

# architectural details - backbones and number of FLAME components
arch:
  backbone_pose: tf_mobilenetv3_small_minimal_100    
  backbone_shape: tf_mobilenetv3_large_minimal_100
  backbone_expression: tf_mobilenetv3_large_minimal_100
  num_expression: 50 
  num_shape: 300 # same as MICA
  use_eyelids: True
  enable_fuse_generator: True 
  enable_temporal_generator: False
  tater_base: True

  TATER:
    interp_down_residual: False
    use_interp_linear_layer: False
    downsample_rate: 3
    apply_linear_after_res: False

    Expression:
      use_base_encoder: False
      use_audio: True
      use_latent: True
      use_linear: True
      linear_size: 320
      use_linear_downsample: True
      add_to_flame: True
      init_near_zero: True
      init_scale: 1e-9
      pretrain_path: ""                                        

      CrossAttentionTransformer:
        positional_embedding: "Sinusoidal"
        num_layers: 3
        cross_layers: 1
        concat_layers: 1
        encoder_1_mask_rate: 1.0
        encoder_2_mask_rate: 0.8

        final_dropout:
          enable: False
          prob: 0.1

        attention:
          d_model_1: 364
          d_model_2: 364
          d_model_C: 728

          dim_feedforward_1: 728
          dim_feedforward_2: 728
          dim_feedforward_C: 1456

          num_attention_heads: 4
          dropout: 0.1

          layer_norm_eps: 1e-12
    Shape:
      use_base_encoder: False
      use_linear: True
      use_latent: True
      add_to_flame: True
      linear_size: 320
      use_linear_downsample: True
      init_near_zero: False
      init_scale: 1e-9
      pretrain_path: "/local/PTSD_STOP/TATER/logs/train_shape_final_v2/model_0_5000.pt"

      Transformer:
        positional_embedding: "Sinusoidal"
        num_layers: 5

        final_dropout:
          enable: False
          prob: 0.1
        
        attention:
          hidden_size: 320
          hidden_size_2: 640
          num_attention_heads: 4
          attention_probs_dropout_prob: 0.1

          layer_norm_eps: 1e-12

    Pose:
      use_base_encoder: False
      use_linear: True
      use_latent: True
      add_to_flame: True
      linear_size: 192
      use_linear_downsample: True
      init_near_zero: False
      init_scale: 1e-9
      pretrain_path: "/local/PTSD_STOP/TATER/logs/train_pose_final_v2/model_0_16799.pt"

      Transformer:
        positional_embedding: "Sinusoidal"
        num_layers: 5

        final_dropout:
          enable: False
          prob: 0.1
        
        attention:
          hidden_size: 192
          hidden_size_2: 384
          num_attention_heads: 4
          attention_probs_dropout_prob: 0.1

          layer_norm_eps: 1e-12

    text_emb_size: 768

  Phoneme_Classifier:
    enable: False
    type: "Linear"
    use_latent: True
    Transformer:
          positional_embedding: "Sinusoidal"
          num_layers: 2

          final_dropout:
            enable: False
            prob: 0.1
          
          attention:
            hidden_size: 56
            hidden_size_2: 112
            num_attention_heads: 2
            attention_probs_dropout_prob: 0.1

            layer_norm_eps: 1e-12


render:
  full_head: False  # full FLAME rendering

dataset:
  iHiTOP:
    hdf5_path: /local/PTSD_STOP/iHiTOP_Preprocessed/data
    frame_step: 1
    max_data_idxs: 360000

    # Data culling parameters
    removed_frames_threshold: 0.1
    max_seg_len: 9999999
    min_seg_len: 9
    data_idxs: /local/PTSD_STOP/TATER/data_idxs/all_data_idxs_FINAL_300K.npy
    # all_seg_idxs: /local/PTSD_STOP/TATER/data_idxs/all_seg_idxs_F3.npy
    # effective_seg_count: /local/PTSD_STOP/TATER/data_idxs/all_data_count_F3.npy
    final_idxs_train: /local/PTSD_STOP/TATER/final_idxs/all_data_idxs_FINAL_300K_train.npy
    final_idxs_val: /local/PTSD_STOP/TATER/final_idxs/all_data_idxs_FINAL_300K_val.npy
    final_idxs_test: /local/PTSD_STOP/TATER/final_idxs/all_data_idxs_FINAL_300K_test.npy
    final_mask_train: /local/PTSD_STOP_pk/train_mask.npy
    final_mask_val: /local/PTSD_STOP_pk/val_mask.npy
    final_mask_test: /local/PTSD_STOP_pk/test_mask.npy
    bad_files: /local/PTSD_STOP/TATER/final_idxs/all_data_idxs_FINAL_300K_bad_files.npy

    # percentage of data to use for train val test
    train_percentage: 0.84
    val_percentage: 0.08
    test_percentage: 0.08

  VOCASET:
    data_path: /home/arivero/VOCA
    frame_step: 1

    # Data culling parameters
    removed_frames_threshold: 0.15
    max_seg_len: 9999999
    min_seg_len: 3
    final_idxs: /local/PTSD_STOP/TATER/final_idxs/all_final_idxs_VOCASET.npy

    # percentage of data to use for train val test
    train_percentage: 1.0
    val_percentage: 0.0
    test_percentage: 0.0

  EXT:
    data_path: /home/arivero/SB_Val/data
    frame_step: 1

    # percentage of data to use for train val test
    train_percentage: 0.0
    val_percentage: 1.0
    test_percentage: 0.0

  # percentage of data to use for each dataset
  LRS3_percentage: 0.0
  LRS3_temporal_sampling: False
  MEAD_percentage: 1.0
  FFHQ_percentage: 0.0 
  CelebA_percentage: 0.0 
  MEAD_sides_percentage: 0.0
  sample_full_video_for_testing: False

